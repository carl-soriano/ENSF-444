{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "<font size=\"+3\"><b>Assignment 2: Linear Models and Validation Metrics</b></font>\n",
        "\n",
        "***\n",
        "* **Full Name** = Carl Soriano\n",
        "* **UCID** = 30125643 \n",
        "*** "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Blue'>In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.</font>\n",
        "\n",
        "You can use the Table of Content on the left side of this notebook to efficiently navigate within this documents.\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|         **Part 1: Classification**         |           |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |     1     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement Machine Learning   Model |           |\n",
        "|           Step 4: Validate Model           |           |\n",
        "|          Step 5: Visualize Results         |     4     |\n",
        "|                  Questions                 |     4     |\n",
        "|             Process Description            |     4     |\n",
        "|           **Part 2: Regression**           |           |\n",
        "|             Step 1: Data Input             |     1     |\n",
        "|           Step 2: Data Processing          |    0.5    |\n",
        "| Step 3: Implement Machine Learning   Model |     1     |\n",
        "|            Step 4: Validate Mode           |     1     |\n",
        "|          Step 5: Visualize Results         |     1     |\n",
        "|                  Questions                 |     2     |\n",
        "|             Process Description            |     4     |\n",
        "|  **Part 3:   Observations/Interpretation** |   **3**   |\n",
        "|           **Part 4: Reflection**           |   **2**   |\n",
        "|                  **Total**                 |   **30**  |\n",
        "|                                            |           |\n",
        "|                  **Bonus**                 |           |\n",
        "|         **Part 5: Bonus Question**         |   **4**   |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 1: Classification (14.5 marks total)**\n",
        "\n",
        "|                **Question**                | **Point** |\n",
        "|:------------------------------------------:|:---------:|\n",
        "|         **Part 1: Classification**         |           |\n",
        "|          Step 0: Import Libraries          |           |\n",
        "|             Step 1: Data Input             |     1     |\n",
        "|           Step 2: Data Processing          |    1.5    |\n",
        "| Step 3: Implement Machine Learning   Model |           |\n",
        "|           Step 4: Validate Model           |           |\n",
        "|          Step 5: Visualize Results         |     4     |\n",
        "|                  Questions                 |     4     |\n",
        "|             Process Description            |     4     |\n",
        "|                  **Total**                 |  **14.5** |\n",
        "\n",
        "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3c6fc8",
      "metadata": {
        "id": "7e3c6fc8"
      },
      "source": [
        "## **Step 0:** Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "33f86925",
      "metadata": {
        "id": "33f86925"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-59ab05e21164>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67"
      },
      "outputs": [],
      "source": [
        "# TO DO: Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_spam #https://www.scikit-yb.org/en/latest/api/datasets/index.html\n",
        "\n",
        "X, y = load_spam()\n",
        "\n",
        "# TO DO: Print size and type of X and y\n",
        "# print(X.head())\n",
        "# print(y)\n",
        "print(\"Size and type of X: \", X.size, type(X))\n",
        "print(\"Size and type of y: \", y.size, type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing (1.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e7204f5",
      "metadata": {
        "id": "4e7204f5"
      },
      "outputs": [],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "#Check for missing values in X\n",
        "missing_values = X.isnull().sum().sum()\n",
        "\n",
        "if missing_values > 0:\n",
        "    print(\"Missing values in the dataset.\")\n",
        "    #Filling missing values\n",
        "    X.fillna(X.mean(), inplace=True)\n",
        "    print(\"Missing values filled in.\")\n",
        "else:\n",
        "    print(\"No missing values in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a489285a",
      "metadata": {
        "id": "a489285a"
      },
      "source": [
        "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bc4a23",
      "metadata": {
        "id": "f9bc4a23"
      },
      "outputs": [],
      "source": [
        "# TO DO: Create X_small and y_small\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_small, y_train, y_small = train_test_split(X, y, test_size= 0.95, random_state=42)\n",
        "\n",
        "print(X_small.size)\n",
        "print(y_small.size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with three different datasets:\n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89f3d84",
      "metadata": {
        "id": "b89f3d84"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352106a3",
      "metadata": {
        "id": "352106a3"
      },
      "source": [
        "## **Step 5:** Visualize Results (4 marks for steps 3-5)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "from sklearn.linear_model import LogisticRegression #https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = LogisticRegression(max_iter=2000,random_state=0)\n",
        "X_first_columns = X.iloc[:, :2]\n",
        "\n",
        "\n",
        "#STEP 4\n",
        "def calculate_accuracy(X_train, y_train,X_test,y_test):\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  train_accuracy = accuracy_score(y_train,model.predict(X_train))\n",
        "  val_accuracy = accuracy_score(y_test,model.predict(X_test))\n",
        "\n",
        "  return train_accuracy,val_accuracy\n",
        "\n",
        "\n",
        "#STEP 5\n",
        "datasets = [(X, y, X_small,y_small,\"Complete dataset \"), (X_first_columns, y, X_small.iloc[:, :2], y_small, \"First two columns of X and y\"), (X_train, y_train, X_small, y_small, \"Small dataset\")]\n",
        "\n",
        "results = pd.DataFrame(columns=['Data size', 'Training accuracy', 'Validation accuracy'])\n",
        "\n",
        "for X_data, y_data, X_test, y_test, name in datasets:\n",
        "  train_accuracy, val_accuracy = calculate_accuracy(X_data, y_data, X_test, y_test)\n",
        "\n",
        "  results.loc[name] = [X_data.size, train_accuracy, val_accuracy]\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4427d4f",
      "metadata": {
        "id": "d4427d4f"
      },
      "source": [
        "## **Questions (4 marks)**\n",
        "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
        "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
        "\n",
        "<font color='Green'><b>YOUR ANSWERS HERE</b></font>\n",
        "\n",
        "1. The complete dataset, including both training and validation sets, achieves a high 93% accuracy, outperforming the results obtained with only two data columns and the smaller dataset. The reduction in data noticeably drops the accuracy to 61% for both training and validation. Interestingly, the training accuracy with the smaller dataset reaches the highest at 96%.\n",
        "\n",
        "2. In part 1 of this assignment, the dataset focuses on spam detection. A false positive occurs when the model incorrectly predicts non-spam as spam, while a false negative happens when the model mistakenly classifies spam as non-spam. The significance lies in the potential consequences: a false positive, where an important and time-sensitive email is wrongly labeled as spam, can have adverse effects in certain situations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7559517a",
      "metadata": {
        "id": "7559517a"
      },
      "source": [
        "## **Process Description (4 marks)**\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fe687f",
      "metadata": {
        "id": "59fe687f"
      },
      "source": [
        "<font color='Green'><b>DESCRIBE YOUR PROCESS HERE</b></font> \n",
        "\n",
        "1. I incorporated code from the official scikit-learn documentation, as indicated in the comments of my code where I provided the relevant link. Additionally, I referred to lecture slides and lab files to guide the development of the machine learning models and to calculate training and validation accuracy.\n",
        "\n",
        "2. Initially, I completed steps 1 and 2. I revisited lab 2 and lab 3, realizing that they helped with the assignment requirements. I adapted the existing code from the labs to meet the specific needs of the assignment. I reviewed lecture slides and clarified concepts, enabling me to apply them effectively to the assignment. I followed a systematic approach, progressing from step 1 to step 5.\n",
        "\n",
        "3. For step 2, I encountered a challenge in recalling the exact method to check for missing values in the dataset. When I got this problem, I tried to figure it out on my own, then got assistance from ChatGPT, which suggested using `.sum()` to identify missing values and provided an if statement to handle them. Since I have worked with with this function from past use, I was able to fix my problem. \n",
        "\n",
        "4. It wasnt that I faced any challenges, it was that the learning something new and then applying it to an assignment took some time. I just went to the labs and they helped a lot. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4c78a8",
      "metadata": {
        "id": "fb4c78a8"
      },
      "source": [
        "# **Part 2: Regression (10.5 marks total)**\n",
        "\n",
        "| **Question**                               | **Point** |\n",
        "|--------------------------------------------|-----------|\n",
        "| **Part 2: Regression**                     |           |\n",
        "| Step 1: Data Input                         | 1         |\n",
        "| Step 2: Data Processing                    | 0.5       |\n",
        "| Step 3: Implement Machine Learning   Model | 1         |\n",
        "| Step 4: Validate Mode                      | 1         |\n",
        "| Step 5: Visualize Results                  | 1         |\n",
        "| Questions                                  | 2         |\n",
        "| Process Description                        | 4         |\n",
        "| **Total**                                  | **10.5**  |\n",
        "\n",
        "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ba83c5",
      "metadata": {
        "id": "b2ba83c5"
      },
      "source": [
        "## **Step 1:** Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff2e34f",
      "metadata": {
        "id": "6ff2e34f"
      },
      "outputs": [],
      "source": [
        "# TO DO: Import concrete dataset from yellowbrick library\n",
        "# TO DO: Print size and type of X and y\n",
        "from yellowbrick.datasets import load_concrete\n",
        "\n",
        "X2, y2 = load_concrete()\n",
        "\n",
        "# print(dir(data))\n",
        "print(\"Size and type of X: \", X2.size, type(X2))\n",
        "print(\"Size and type of y: \", y2.size, type(y2))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5294cfa",
      "metadata": {
        "id": "c5294cfa"
      },
      "source": [
        "## **Step 2:** Data Processing (0.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693c5fa3",
      "metadata": {
        "id": "693c5fa3"
      },
      "outputs": [],
      "source": [
        "# TO DO: Check if there are any missing values and fill them in if necessary\n",
        "missing_values = X2.isnull().sum().sum()\n",
        "\n",
        "if missing_values > 0:\n",
        "    print(\"Missing values in the dataset.\")\n",
        "    #Filling missing values\n",
        "    print(\"Missing values filled in.\")\n",
        "else:\n",
        "    print(\"No missing values in the dataset.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc60489",
      "metadata": {
        "id": "1bc60489"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model (1 mark)\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "suiGuK-W1WnL",
      "metadata": {
        "id": "suiGuK-W1WnL"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "from sklearn.linear_model import LinearRegression #https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "model2 = LinearRegression()\n",
        "\n",
        "X2_train, X2_val, y2_train, y2_val = train_test_split(X2, y2, test_size=0.2, random_state=0)\n",
        "model2.fit(X2_train, y2_train) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de28482",
      "metadata": {
        "id": "1de28482"
      },
      "source": [
        "## **Step 4:** Validate Model (1 mark)\n",
        "\n",
        "Calculate the training and validation accuracy using mean squared error and R2 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970c038b",
      "metadata": {
        "id": "970c038b"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "y2_train_pred = model2.predict(X2_train)\n",
        "y2_val_pred = model2.predict(X2_val)\n",
        "\n",
        "mse_train = mean_squared_error(y2_train, y2_train_pred)\n",
        "mse_val = mean_squared_error(y2_val, y2_val_pred)\n",
        "\n",
        "r2_train = r2_score(y2_train, y2_train_pred)\n",
        "r2_val = r2_score(y2_val, y2_val_pred)\n",
        "\n",
        "#adding print statements just to check if it was calculating properly\n",
        "print(\"--------Training set--------\")\n",
        "print(\"Mean Squared Error: \", mse_train)\n",
        "print(\"R2 Score: \", r2_train, \"\\n\")\n",
        "print(\"--------Validation set--------\")\n",
        "print(\"Mean Squared Error: \", mse_val)\n",
        "print(\"R2 Score: \", r2_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa7795",
      "metadata": {
        "id": "54aa7795"
      },
      "source": [
        "## **Step 5:** Visualize Results (1 mark)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d223f3",
      "metadata": {
        "id": "88d223f3"
      },
      "outputs": [],
      "source": [
        "# TO DO: ADD YOUR CODE HERE\n",
        "\n",
        "results2 = pd.DataFrame(index=['MSE', 'R2 score'], columns=['Training accuracy', 'Validation accuracy'])\n",
        "\n",
        "results2.loc['MSE'] = [mse_train, mse_val]\n",
        "results2.loc['R2 score'] = [r2_train, r2_val]\n",
        "\n",
        "results2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a42bda",
      "metadata": {
        "id": "70a42bda"
      },
      "source": [
        "## **Questions (2 marks)**\n",
        "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
        "\n",
        "No, the linear model did not produce good results since the R2 Score was ~60% for training and validation accuracy which is not close to 100% meaning that the fit is not good enough. In addition, the MSE is high but for MSE, the lower it is the better because it represents how good the fit of the model is."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca0ff2f",
      "metadata": {
        "id": "2ca0ff2f"
      },
      "source": [
        "## **Process Description (4 marks)**\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdb0880",
      "metadata": {
        "id": "dfdb0880"
      },
      "source": [
        "<font color='Green'><b>Explain YOUR PROCESS here:</b></font>\n",
        "\n",
        "1. Applied the same work method I did for part 1 because the workflow was kind of similar. \n",
        "\n",
        "2. For steps 1-2, I essentially replicated the code from part 1, making adjustments to accommodate the new dataset and have different variable names. Subsequently, for steps 3-5, I adopted a similar approach as in part 1, with the process being simpler this time as we only had one model to deal with.\n",
        "\n",
        "3. For part 2 of the assignment I didn't prompt ChatGPT for anything since everything was basically done in part 1 already.\n",
        "\n",
        "4. NO challenges because this was similar to part 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72ac3eb",
      "metadata": {
        "id": "e72ac3eb"
      },
      "source": [
        "# **Part 3: Observations/Interpretation (3 marks)**\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "<font color='Green'><b>ADD YOUR FINDINGS HERE</b></font>\n",
        "\n",
        "For the logistic regression model, the training and validation accuracy approached 1 when utilizing the complete dataset, indicating a well-fitted model for the spam dataset. However, when applied to the concrete dataset, the model's accuracy was suboptimal, suggesting that a linear model might not be the most suitable fit for this particular dataset. The results co-relate with discussions from lectures, highlight the potential consequences of a low R2 score, leading to a high MSE score, thereby indicating a poor model fit.\n",
        "\n",
        "Comparing parts 1 and 2, it's evident that accuracy significantly declined even with both models being linear, dropping from around 90% to approximately 60%. This emphasizes the crucial role of the dataset, indicating that linear models may not consistently give optimal results across all datasets. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b84eed",
      "metadata": {
        "id": "40b84eed"
      },
      "source": [
        "# **Part 4: Reflection (2 marks)**\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "<font color='Green'><b>ADD YOUR THOUGHTS HERE</b></font>\n",
        "\n",
        "I liked that we are actually applying what we are learning from the labs and lectures to the assingments. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db951b3a",
      "metadata": {
        "id": "db951b3a"
      },
      "source": [
        "# **Part 5: Bonus Question (4 marks)**\n",
        "\n",
        "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
        "\n",
        "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47623d44",
      "metadata": {
        "id": "47623d44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "1b606236",
      "metadata": {
        "id": "1b606236"
      },
      "source": [
        "<font color='Green'><b>ADD YOUR ANSWER HERE</b></font>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "05ece30799c2dcdac4c13b3af20453da19de8df0d9a1de52cff7e0b6e1e82bdd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
